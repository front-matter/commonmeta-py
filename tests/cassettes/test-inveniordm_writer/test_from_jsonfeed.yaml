interactions:
- request:
    body: null
    headers:
      Accept:
      - '*/*'
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - python-requests/2.32.5
    method: GET
    uri: https://api.rogue-scholar.org/posts/525a7d13-fe07-4cab-ac54-75d7b7005647
  response:
    body:
      string: '{"abstract":"A preprint claims that \u201cideas from theoretical linguistics
        have played no role in [NLP]\u201d. Outside the confines of Chomskyan linguistics
        folks have long been working on  incorporating storage, retrieval, gating
        and attention in theories of language, with direct relevance to computational
        models. The only way to give any content to the claim is by giving the notion
        \u201ctheoretical linguistics\u201d the narrowest conceivable reading.","archive_url":null,"authors":[{"name":"Mark
        Dingemanse"}],"blog":{"archive_collection":24087,"archive_host":null,"archive_prefix":null,"archive_timestamps":null,"authors":null,"canonical_url":null,"category":"languagesAndLiterature","community_id":"ac7a6214-f166-416e-9500-caa8343d6285","created_at":1706627953,"current_feed_url":null,"description":"Sounding
        out ideas on language, interaction, and iconicity","doi_as_guid":false,"favicon":"https://rogue-scholar.org/api/communities/ac7a6214-f166-416e-9500-caa8343d6285/logo","feed_format":"application/atom+xml","feed_url":"https://ideophone.org/feed/atom/","filter":"category:98","funding":null,"generator":"WordPress","generator_raw":"WordPress
        6.7.1","home_page_url":"https://ideophone.org/","id":"191184bc-efcf-4f0f-a1ee-09436542d408","indexed":true,"issn":null,"language":"en","license":"https://creativecommons.org/licenses/by/4.0/legalcode","mastodon":"https://scholar.social/@dingemansemark","prefix":"10.59350","registered_at":1728774318,"relative_url":null,"ror":null,"secure":true,"slug":"ideophone","status":"active","subfield":"1203","title":"The
        Ideophone","updated_at":1764078313,"use_api":true,"use_mastodon":false,"user_id":"e1f022f2-7d98-4b1e-81cc-81d8e8416403"},"blog_name":"The
        Ideophone","blog_slug":"ideophone","content_html":"\n<p>This <a rel=\"noreferrer
        noopener\" href=\"https://ling.auf.net/lingbuzz/006031\" target=\"_blank\">Lingbuzz
        preprint by Baroni</a> is a nice read if you&#8217;re interested in linguistically
        oriented deep net analysis. I did feel it&#8217;s a bit hampered by the near-exclusive
        equation of linguistic theory with generative/Chomskyan aps. (I know it makes
        a point of claiming a &#8220;very broad notion of theoretical linguistics&#8221;,
        but it doesn&#8217;t really demonstrate this, and throughout the implicit
        notion of theory is near-exclusively aligned with GG and its associated concerns
        of competence, poverty of the stimulus, et cetera).</p>\n\n\n\n<figure class=\"wp-block-image\"><img
        decoding=\"async\" src=\"https://pbs.twimg.com/media/E4FDxONXwAMFvCh.png\"
        alt=\"\"/></figure>\n\n\n\n<p>For instance, it notes (citing Lappin) that
        theoretical linguistics &#8220;played no role&#8221; in deep learning for
        NLP, but while this may hold for generative grammar (GG), linguistic theorizing
        was much broader than that right at the start of connectionism and RNNs, e.g.
        in <a href=\"http://doi.org/10.1023/A:1022699029236\" target=\"_blank\" rel=\"noreferrer
        noopener\">Elman 1991</a>.</p>\n\n\n\n<p>In fact, just look at the bibliography
        of Elman&#8217;s classic RNN work and tell us again how exactly theoretical
        linguistics &#8220;played no role&#8221; \u2014  Bates &amp; Macwhinney, Chomsky,
        Fillmore, Fodor, Givon, Hopper &amp; Thompson, Lakoff, Langacker, they&#8217;re
        all there. Elman&#8217;s bibliography is a virtual <em>Who is Who</em> of
        big tent linguistics at the start of the 1990s. The only way to give any content
        to Lappin&#8217;s claim (and by extension, Baroni&#8217;s generalization)
        is to give the notion of &#8220;theoretical linguistics&#8221; the narrowest
        conceivable reading.</p>\n\n\n\n<figure class=\"wp-block-gallery has-nested-images
        columns-default is-cropped wp-block-gallery-3 is-layout-flex wp-block-gallery-is-layout-flex\">\n<figure
        class=\"wp-block-image size-large\"><a href=\"https://ideophone.org/files/E4FEkLuWUAI6IwO.png\"><img
        loading=\"lazy\" decoding=\"async\" width=\"696\" height=\"1024\" data-id=\"5640\"
        src=\"https://ideophone.org/files/E4FEkLuWUAI6IwO-696x1024.png\" alt=\"\"
        class=\"wp-image-5640\" srcset=\"https://ideophone.org/files/E4FEkLuWUAI6IwO-696x1024.png
        696w, https://ideophone.org/files/E4FEkLuWUAI6IwO-204x300.png 204w, https://ideophone.org/files/E4FEkLuWUAI6IwO.png
        754w\" sizes=\"auto, (max-width: 696px) 100vw, 696px\" /></a></figure>\n</figure>\n\n\n\n<p>However,
        Baroni&#8217;s point may generalize: perhaps modern-day usage-based, functional,
        and cognitive approaches to ling theory aren&#8217;t drawing as heavily on
        current NLP/ML/DL work as they could either. Might a lack of reciprocity play
        a role? After all, the well known ahistoricism and lack of interdisciplinary
        engagement of NLP today does not exactly invite productive exchange. (Though
        some of us try.)</p>\n\n\n\n<p>The theory=Chomsky equation also makes it appearance
        at the end, where Baroni muses about  incorporating storage, retrieval, gating
        and attention in theories of language. Outside the confines of Chomskyan linguistics
        folks have long been working on precisely such things. One might think work
        by Joan Bybee, Maryellen MacDonald, Morten Christiansen, and others might
        merit a mention!</p>\n\n\n\n<figure class=\"wp-block-image\"><img decoding=\"async\"
        src=\"https://pbs.twimg.com/media/E4FH0LUXwAY9NfF.png\" alt=\"\"/></figure>\n\n\n\n<p>In
        sum, Baroni&#8217;s piece provides an informative if partial review of recent
        work and includes bold proposals (e.g., deep nets as algorithmic linguistic
        theories), worth reading if you&#8217;re interested in a particular kind of
        linguistics. Consider pairing it with this <a href=\"http://doi.org/10.1023/A:1022699029236\"
        target=\"_blank\" rel=\"noreferrer noopener\">well-aged bottle of Elman 1991</a>!</p>\n\n\n\n<h2
        class=\"heading\" class=\"wp-block-heading\">References</h2>\n\n\n\n<ul class=\"wp-block-list\">\n<li>Baroni,
        M. (2021, June). <em>On the proper role of linguistically-oriented deep net
        analysis in linguistic theorizing</em>. LingBuzz. Retrieved from <a href=\"https://ling.auf.net/lingbuzz/006031\">https://ling.auf.net/lingbuzz/006031</a></li>\n\n\n\n<li>Bybee,
        J. L. (2010). <em>Language, Usage, and Cognition</em>. Cambridge: Cambridge
        University Press.</li>\n\n\n\n<li>Christiansen, M. H., &amp; Chater, N. (2017).
        Towards an integrated science of language. <em>Nature Human Behaviour</em>,
        <em>1</em>, s41562-017-0163\u2013017. doi: <a href=\"https://doi.org/10.1038/s41562-017-0163\">10.1038/s41562-017-0163</a></li>\n\n\n\n<li>Elman,
        J. L. (1991). Distributed Representations, Simple Recurrent Networks, And
        Grammatical Structure. <em>Machine Learning</em>, <em>7</em>, 195\u2013225.
        doi: <a href=\"https://doi.org/10.1023/A:1022699029236\">10.1023/A:1022699029236</a></li>\n\n\n\n<li>Lappin,
        S. (2021). <em>Deep learning and linguistic representation</em>. Boca Raton:
        CRC Press.</li>\n\n\n\n<li>MacDonald, M. C., &amp; Christiansen, M. H. (2002).
        Reassessing working memory: Comment on Just and Carpenter (1992) and Waters
        and Caplan (1996). <em>Psychological Review</em>, <em>109</em>(1), 35\u201354.
        doi: <a href=\"https://doi.org/10.1037/0033-295X.109.1.35\">10.1037/0033-295X.109.1.35</a></li>\n</ul>\n\n\n\n<p><em>Originally
        tweeted by <a rel=\"mention\" class=\"u-url mention\" href=\"https://scholar.social/@dingemansemark\">@<span>dingemansemark</span></a>
        (<a href=\"https://twitter.com/DingemanseMark\">@DingemanseMark</a>) on <a
        href=\"https://twitter.com/DingemanseMark/status/1405488247057391616\">June
        17, 2021</a>.</em></p>\n\n\n\n<p></p>\n","doi":"https://doi.org/10.59350/dn2mm-m9q51","funding_references":null,"guid":"https://ideophone.org/?p=5639","id":"525a7d13-fe07-4cab-ac54-75d7b7005647","image":null,"indexed_at":1741120300,"language":"en","parent_doi":null,"published_at":1626939547,"reference":[{"id":"https://ling.auf.net/lingbuzz/006031","unstructured":"Baroni,
        M. (2021, June). On the proper role of linguistically-oriented deep net analysis
        in linguistic theorizing. LingBuzz. Retrieved from https://ling.auf.net/lingbuzz/006031"},{"unstructured":"Bybee,
        J. L. (2010). Language, Usage, and Cognition. Cambridge: Cambridge University
        Press."},{"id":"https://doi.org/10.1038/s41562-017-0163","type":"JournalArticle","unstructured":"Christiansen,
        M. H., &amp; Chater, N. (2017). Towards an integrated science of language.
        <i>Nature Human Behaviour</i>, <i>1</i>(8). https://doi.org/10.1038/s41562-017-0163"},{"id":"https://doi.org/10.1023/A:1022699029236","unstructured":"Elman,
        J. L. (1991). Distributed Representations, Simple Recurrent Networks, And
        Grammatical Structure. Machine Learning, 7, 195\u2013225. https://doi.org/10.1023/A:1022699029236"},{"unstructured":"Lappin,
        S. (2021). Deep learning and linguistic representation. Boca Raton: CRC Press."},{"id":"https://doi.org/10.1037/0033-295x.109.1.35","type":"JournalArticle","unstructured":"MacDonald,
        M. C., &amp; Christiansen, M. H. (2002). Reassessing working memory: Comment
        on Just and Carpenter (1992) and Waters and Caplan (1996). <i>Psychological
        Review</i>, <i>109</i>(1), 35\u201354. https://doi.org/10.1037/0033-295x.109.1.35"}],"registered_at":0,"relationships":[],"rid":"7tatc-wh557","subfield":null,"summary":"This
        Lingbuzz preprint by Baroni is a nice read if you\u2019re interested in linguistically
        oriented deep net analysis. I did feel it\u2019s a bit hampered by the near-exclusive
        equation of linguistic theory with generative/Chomskyan aps.","tags":["Linguistics","Threads"],"title":"Linguistic
        roots of connectionism","topic":null,"topic_score":0,"updated_at":1707080736,"url":"https://ideophone.org/linguistic-roots-of-connectionism","version":"v1"}

        '
    headers:
      content-encoding:
      - gzip
      content-type:
      - application/json
      date:
      - Mon, 01 Dec 2025 17:18:46 GMT
      fly-request-id:
      - 01KBDES2TN4V27QVV58ZWHDD0V-ams
      ratelimit-limit:
      - '15'
      ratelimit-remaining:
      - '12'
      ratelimit-reset:
      - '11'
      server:
      - Fly/0dca8e971 (2025-11-29)
      transfer-encoding:
      - chunked
      vary:
      - Origin
      via:
      - 1.1 fly.io, 1.1 fly.io
    status:
      code: 200
      message: ''
version: 1
